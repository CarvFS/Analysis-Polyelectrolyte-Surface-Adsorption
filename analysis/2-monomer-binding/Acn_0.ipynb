{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze sampling of the OPES Explore production simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path    \n",
    "import sys\n",
    "\n",
    "# third-party packages\n",
    "import cmasher as cmr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, integrate\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# notebook\n",
    "from IPython import display\n",
    "\n",
    "# get absolute path to file's parent directory\n",
    "dir_proj_base = Path(os.getcwd()).resolve().parents[1]\n",
    "sys.path.insert(0, f\"{dir_proj_base}/src\")\n",
    "\n",
    "# Internal dependencies\n",
    "from utils.figure_style import set_style  # noqa: E402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging and formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook logger has DEBUG level\n",
    "log = logging.getLogger(\"notebook\")\n",
    "log.setLevel(logging.DEBUG)\n",
    "\n",
    "# console handler\n",
    "format = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "ch.setFormatter(format)\n",
    "log.addHandler(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plotting style\n",
    "set_style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set thermal energy\n",
    "TEMPERATURE_K: float = 300  # [K] # system temperature\n",
    "KB = 8.314462618e-3  # [kJ/mol/K]\n",
    "kbt = KB * TEMPERATURE_K  # [kJ/mol]\n",
    "\n",
    "# enhanced sampling parameters\n",
    "hrex = False\n",
    "opes = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate free energy surface at the end of the simulation\n",
    "cv = \"dist_chain.z\"\n",
    "start_frame_perc = 0.10\n",
    "bandwidth = 0.075\n",
    "min_val = 0.8\n",
    "max_val = 2.5\n",
    "\n",
    "# calculate free energy difference between the two states\n",
    "lower_well = (0.7, 0.9)\n",
    "upper_well = (2.0, 2.2)\n",
    "\n",
    "# plotting parameters\n",
    "ymax = 10\n",
    "\n",
    "# animation parameters\n",
    "step = 200\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data input\n",
    "data_dir_base = Path(\"/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Polyelectrolyte-Surface-Adsorption/data\")\n",
    "data_dir = data_dir_base / \"2.2.0-calcite-104surface-5nm_surface-8nm_vertical-1chain-PAcn-1mer-0Crb-0Ca-0Na-0Cl-300K-1bar-NVT/3-sampling-opes-explore\"\n",
    "\n",
    "if hrex:\n",
    "    fname = \"replica_00/COLVAR.0.data\"\n",
    "else:\n",
    "    fname = \"COLVAR.data\"\n",
    "\n",
    "# data output\n",
    "tag = \"Acn-monomer-opes-explore-0\"\n",
    "dir_fig = Path(f\"figures/{tag}\")\n",
    "dir_fig.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plumed_df(file: Path) -> pd.DataFrame:\n",
    "    # input checking\n",
    "    if not isinstance(file, Path):\n",
    "        file = Path(file)\n",
    "    if not file.parent.exists():\n",
    "        raise FileNotFoundError(f\"Directory {file.parent} does not exist\")\n",
    "    if not file.exists():\n",
    "        raise FileExistsError(f\"File {file} does not exist\")\n",
    "\n",
    "    # first line of file contains column names\n",
    "    with open(str(file), encoding=\"utf8\") as f:\n",
    "        header = f.readline()\n",
    "    header = header.split()[2:]  # remove \"#!\" FIELDS\n",
    "    n_cols = len(header)\n",
    "\n",
    "    # read in data\n",
    "    df = pd.read_csv(\n",
    "        str(file),\n",
    "        names=header,\n",
    "        comment=\"#\",\n",
    "        delim_whitespace=True,\n",
    "        skipinitialspace=True,\n",
    "        usecols=list(range(n_cols)),\n",
    "    )\n",
    "\n",
    "    # if duplicate \"time\" rows, keep only the last one\n",
    "    df = df.drop_duplicates(subset=\"time\", keep=\"last\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data for base replica\n",
    "file = data_dir / fname\n",
    "data = plumed_df(file)\n",
    "\n",
    "# read in data for all replicas\n",
    "all_data = []\n",
    "if hrex:\n",
    "    for rep in range(8):\n",
    "        file = data_dir / f\"replica_{rep:02d}/COLVAR.{rep}.data\"\n",
    "        all_data.append(plumed_df(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>dist_chain.x</th>\n",
       "      <th>dist_chain.y</th>\n",
       "      <th>dist_chain.z</th>\n",
       "      <th>opes.bias</th>\n",
       "      <th>opes.rct</th>\n",
       "      <th>opes.zed</th>\n",
       "      <th>opes.neff</th>\n",
       "      <th>opes.nker</th>\n",
       "      <th>opes.work</th>\n",
       "      <th>rg_chain</th>\n",
       "      <th>cn_ca_co</th>\n",
       "      <th>dist_ca.x</th>\n",
       "      <th>dist_ca.y</th>\n",
       "      <th>dist_ca.z</th>\n",
       "      <th>upper_wall.bias</th>\n",
       "      <th>upper_wall.force2</th>\n",
       "      <th>lower_wall.bias</th>\n",
       "      <th>lower_wall.force2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.118763</td>\n",
       "      <td>-0.106855</td>\n",
       "      <td>2.013256</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684820</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.247519</td>\n",
       "      <td>47.176361</td>\n",
       "      <td>0.330457</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-4.166669</td>\n",
       "      <td>-0.112159</td>\n",
       "      <td>2.010992</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713408</td>\n",
       "      <td>0.000333</td>\n",
       "      <td>0.247351</td>\n",
       "      <td>47.176238</td>\n",
       "      <td>0.329344</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-4.190814</td>\n",
       "      <td>-0.007264</td>\n",
       "      <td>1.991104</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.755529</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.248650</td>\n",
       "      <td>47.176471</td>\n",
       "      <td>0.330741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>-4.200050</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>2.038913</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.761707</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.245629</td>\n",
       "      <td>47.174385</td>\n",
       "      <td>0.330410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>-4.191279</td>\n",
       "      <td>-0.024769</td>\n",
       "      <td>2.007873</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>-50.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.684862</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.244264</td>\n",
       "      <td>47.176142</td>\n",
       "      <td>0.331290</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   time  dist_chain.x  dist_chain.y  dist_chain.z  opes.bias  opes.rct  \\\n",
       "0   0.0     -4.118763     -0.106855      2.013256      -50.0     -50.0   \n",
       "1   1.0     -4.166669     -0.112159      2.010992      -50.0     -50.0   \n",
       "2   2.0     -4.190814     -0.007264      1.991104      -50.0     -50.0   \n",
       "3   3.0     -4.200050      0.016284      2.038913      -50.0     -50.0   \n",
       "4   4.0     -4.191279     -0.024769      2.007873      -50.0     -50.0   \n",
       "\n",
       "   opes.zed  opes.neff  opes.nker  opes.work  rg_chain  cn_ca_co  dist_ca.x  \\\n",
       "0       1.0        1.0        0.0        0.0  0.684820  0.000368   0.247519   \n",
       "1       1.0        1.0        0.0        0.0  0.713408  0.000333   0.247351   \n",
       "2       1.0        1.0        0.0        0.0  0.755529  0.000215   0.248650   \n",
       "3       1.0        1.0        0.0        0.0  0.761707  0.000164   0.245629   \n",
       "4       1.0        1.0        0.0        0.0  0.684862  0.000224   0.244264   \n",
       "\n",
       "   dist_ca.y  dist_ca.z  upper_wall.bias  upper_wall.force2  lower_wall.bias  \\\n",
       "0  47.176361   0.330457              0.0                0.0              0.0   \n",
       "1  47.176238   0.329344              0.0                0.0              0.0   \n",
       "2  47.176471   0.330741              0.0                0.0              0.0   \n",
       "3  47.174385   0.330410              0.0                0.0              0.0   \n",
       "4  47.176142   0.331290              0.0                0.0              0.0   \n",
       "\n",
       "   lower_wall.force2  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time\n",
      "dist_chain.x\n",
      "dist_chain.y\n",
      "dist_chain.z\n",
      "opes.bias\n",
      "opes.rct\n",
      "opes.zed\n",
      "opes.neff\n",
      "opes.nker\n",
      "opes.work\n",
      "rg_chain\n",
      "cn_ca_co\n",
      "dist_ca.x\n",
      "dist_ca.y\n",
      "dist_ca.z\n",
      "upper_wall.bias\n",
      "upper_wall.force2\n",
      "lower_wall.bias\n",
      "lower_wall.force2\n",
      "2023-10-25 13:35:28,215 - notebook - INFO - Number of rows: 8841\n",
      "2023-10-25 13:35:28,216 - notebook - INFO - Number of columns: 19\n"
     ]
    }
   ],
   "source": [
    "# print all column names\n",
    "for col in data.columns:\n",
    "    print(col)\n",
    "\n",
    "log.info(f\"Number of rows: {len(data)}\")\n",
    "log.info(f\"Number of columns: {len(data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-25 13:35:28,251 - notebook - INFO - Lower wall position: 0.00 [nm]\n",
      "2023-10-25 13:35:28,252 - notebook - INFO - Upper wall position: 2.80 [nm]\n"
     ]
    }
   ],
   "source": [
    "# find lower wall position by finding maximum z coordinate where lwall.bias > 0\n",
    "lwall = data[\"lower_wall.bias\"]\n",
    "z_lwall = data[\"dist_chain.z\"]\n",
    "z_lwall_max = max(0, z_lwall[lwall > 0].max())\n",
    "log.info(f\"Lower wall position: {z_lwall_max:.2f} [nm]\")\n",
    "\n",
    "# find upper wall position by finding minimum z coordinate where uwall.bias > 0\n",
    "uwall = data[\"upper_wall.bias\"]\n",
    "z_uwall = data[\"dist_chain.z\"]\n",
    "z_uwall_min = z_uwall[uwall > 0].min()\n",
    "log.info(f\"Upper wall position: {z_uwall_min:.2f} [nm]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate statistical weight of each frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def statistical_weight(df: pd.DataFrame, verbose: bool = False) -> None:\n",
    "    \"\"\"Calculate statistical weight of each configuration in-place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Dataframe containing bias columns.\n",
    "    verbose : bool, optional\n",
    "        Whether to print statistical weight information, by default False\n",
    "    \"\"\"\n",
    "    # get all columns ending in \".bias\"\n",
    "    cols = [col for col in df.columns if col.endswith(\".bias\")]\n",
    "    # remove \"metad.bias\" if it exists\n",
    "    if \"metad.bias\" in cols:\n",
    "        cols.remove(\"metad.bias\")\n",
    "    # add \"metad.rbias\" if it exists\n",
    "    if \"metad.rbias\" in df.columns:\n",
    "        cols.append(\"metad.rbias\")\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Found {len(cols)} bias columns named {cols}\")\n",
    "\n",
    "    # calculate bias column as sum of all \".bias\" columns\n",
    "    df[\"bias\"] = df[cols].sum(axis=1).astype(np.float128)\n",
    "    # non-dimensionalize bias by kbt\n",
    "    df[\"bias_nondim\"] = (df[\"bias\"] - np.nanmax(df[\"bias\"])) / kbt\n",
    "    # calculate statistical weight as boltzmann factor of bias\n",
    "    df[\"weight\"] = np.exp(df[\"bias_nondim\"])\n",
    "    # normalize weight column to be a probability distribution\n",
    "    df[\"weight\"] /= df[\"weight\"].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 bias columns named ['opes.bias', 'upper_wall.bias', 'lower_wall.bias']\n",
      "2023-10-25 13:35:28,315 - notebook - INFO - Calculating weight column from biases\n",
      "2023-10-25 13:35:28,315 - notebook - DEBUG - (min, max) weight: (0.0, 1.0)\n",
      "2023-10-25 13:35:28,316 - notebook - DEBUG - (0.25, 0.75) weight: (0.0, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# calculate overall bias\n",
    "statistical_weight(data, verbose=True)\n",
    "\n",
    "log.info(\"Calculating weight column from biases\")\n",
    "log.debug(f\"(min, max) weight: ({np.nanmin(data['weight'])}, {np.nanmax(data['weight'])})\")\n",
    "log.debug(f\"(0.25, 0.75) weight: ({np.nanpercentile(data['weight'], 25)}, {np.nanpercentile(data['weight'], 75)})\")\n",
    "\n",
    "# calculate overall bias for all replicas\n",
    "if hrex:\n",
    "    for rep in range(8):\n",
    "        statistical_weight(all_data[rep], verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of the bias potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fig_bias_dynamics(df: pd.DataFrame, fname: str) -> plt.Figure:\n",
    "    fig = plt.figure(figsize=(22, 9))\n",
    "\n",
    "    # CV: curve should show rapid sampling of the entire CV space\n",
    "    ax1 = fig.add_subplot(241)\n",
    "    ax1.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax1.set_ylabel(\"$z$ [nm]\", labelpad=10)\n",
    "    ax1.set_title(\"Collective Variable\", pad=10)\n",
    "    ax1.scatter(df[\"time\"]/1e3, df[\"dist_chain.z\"], s=2, alpha=0.2)\n",
    "\n",
    "    # OPES Bias: bias should be slowly increasing over time\n",
    "    ax2 = fig.add_subplot(242)\n",
    "    ax2.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax2.set_ylabel(\"OPES Bias [kJ/mol]\", labelpad=10)\n",
    "    ax2.set_title(\"OPES Bias\", pad=10)\n",
    "    ax2.scatter(df[\"time\"]/1e3, df[\"opes.bias\"], s=2, alpha=0.2)\n",
    "\n",
    "    # Lower wall bias: should hopefully be near zero for most of the simulation\n",
    "    ax7 = fig.add_subplot(243)\n",
    "    ax7.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax7.set_ylabel(\"Bias [kJ/mol]\", labelpad=10)\n",
    "    ax7.set_title(\"Lower Wall Bias\", pad=10)\n",
    "    ax7.scatter(df[\"time\"]/1e3, df[\"lower_wall.bias\"], s=2, alpha=0.2)\n",
    "\n",
    "    # Upper wall bias: should hopefully be near zero for most of the simulation \n",
    "    ax8 = fig.add_subplot(244)\n",
    "    ax8.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax8.set_ylabel(\"Bias [kJ/mol]\", labelpad=10)\n",
    "    ax8.set_title(\"Upper Wall Bias\", pad=10)\n",
    "    ax8.scatter(df[\"time\"]/1e3, df[\"upper_wall.bias\"], s=2, alpha=0.2)\n",
    "\n",
    "    # OPES time constant: should increase and converge to a constant as the bias becomes quasi-static\n",
    "    ax3 = fig.add_subplot(245)\n",
    "    ax3.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax3.set_ylabel(\"$c{(t)}$\", labelpad=10)\n",
    "    ax3.set_title(\"Quasi-Static Bias\", pad=10)\n",
    "    ax3.plot(df[\"time\"]/1e3, df[\"opes.rct\"], linewidth=3)\n",
    "\n",
    "    # OPES normalization constant: starts from 1 an changes significantly when a new region of CV space is explored\n",
    "    ax4 = fig.add_subplot(246)\n",
    "    ax4.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax4.set_ylabel(\"$Z_n$\", labelpad=10)\n",
    "    ax4.set_title(\"CV Exploration\", pad=10)\n",
    "    ax4.plot(df[\"time\"]/1e3, df[\"opes.zed\"], linewidth=3)\n",
    "\n",
    "    # OPES number of effective samples: should be increasing over time with a fixed ratio to the number of samples\n",
    "    ax5 = fig.add_subplot(247)\n",
    "    ax5.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax5.set_ylabel(\"$n_\\mathrm{eff}$\", labelpad=10)\n",
    "    ax5.set_title(\"Effective Sample Size\", pad=10)\n",
    "    ax5.plot(df[\"time\"]/1e3, df[\"opes.neff\"], linewidth=3)\n",
    "\n",
    "    # OPES number of compressed kernels: should increase and plateau\n",
    "    ax6 = fig.add_subplot(248)\n",
    "    ax6.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "    ax6.set_ylabel(\"$n_\\mathrm{ker}$\", labelpad=10)\n",
    "    ax6.set_title(\"Compressed Kernels\", pad=10)\n",
    "    ax6.plot(df[\"time\"]/1e3, df[\"opes.nker\"], linewidth=3)\n",
    "\n",
    "    # save figure\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{dir_fig}/{fname}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    fig.savefig(f\"{dir_fig}/{fname}.pdf\", dpi=1200, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bias dynamics for base replica\n",
    "fname = \"bias_dynamics\"\n",
    "\n",
    "if opes:\n",
    "    fig = fig_bias_dynamics(data, fname)\n",
    "else:\n",
    "    fig = plt.figure()\n",
    "\n",
    "# display figure\n",
    "plt.close(fig)\n",
    "if opes:\n",
    "    display.Image(f\"{dir_fig}/{fname}.png\", width=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot bias dynamics for all replicas\n",
    "if hrex and opes:\n",
    "    for rep in range(8):\n",
    "        fname = f\"bias_dynamics_replica_{rep:02d}\"\n",
    "        fig = fig_bias_dynamics(all_data[rep], fname)\n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the collective variable for all replicas\n",
    "fig = plt.figure(figsize=(20, 9))\n",
    "fname = \"cv_dynamics\"\n",
    "\n",
    "if hrex:\n",
    "    for i in range(8):\n",
    "        ax = fig.add_subplot(2, 4, i+1)\n",
    "        ax.set_xlabel(\"Time [ns]\", labelpad=10)\n",
    "        ax.set_ylabel(\"$z$ [nm]\", labelpad=10)\n",
    "        ax.set_title(f\"Replica {i+1}\", pad=10)\n",
    "        ax.scatter(all_data[i][\"time\"]/1e3, all_data[i][\"dist_chain.z\"], s=1, alpha=0.2)\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # save figure\n",
    "    fig.savefig(f\"{dir_fig}/{fname}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "    fig.savefig(f\"{dir_fig}/{fname}.pdf\", dpi=1200, bbox_inches=\"tight\", transparent=True)\n",
    "\n",
    "# display figure\n",
    "plt.close(fig)\n",
    "if hrex:\n",
    "    display.Image(f\"{dir_fig}/{fname}.png\", width=1200)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of the free energy surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fes_dist(\n",
    "        x: np.ndarray, \n",
    "        weights: np.ndarray = None, \n",
    "        bandwidth: float = 0.1,\n",
    "        min_val: float = None,\n",
    "        max_val: float = None,\n",
    "    ) -> tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Calculate the free energy surface for a given distance collective variable.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : np.ndarray\n",
    "        Array of distances.\n",
    "    weights : np.ndarray, optional\n",
    "        Array of weights, by default None\n",
    "    bandwidth : float, optional\n",
    "        Bandwidth for kernel density estimation, by default 0.1\n",
    "    min_val : float, optional\n",
    "        Minimum value of distance, by default None\n",
    "    max_val : float, optional\n",
    "        Maximum value of distance, by default None\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    tuple[np.ndarray, np.ndarray]\n",
    "        Tuple of arrays of distances and free energies.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `min_val` is not less than `max_val`.\n",
    "    \"\"\"\n",
    "    # input checking\n",
    "    if min_val is None:\n",
    "        min_val = np.nanmin(x)\n",
    "    if max_val is None:\n",
    "        max_val = np.nanmax(x)\n",
    "    if min_val >= max_val:\n",
    "        raise ValueError(f\"min_val ({min_val}) must be less than max_val ({max_val})\")\n",
    "    \n",
    "    # calculate KDE of x weighted by weights\n",
    "    x_grid = np.linspace(min_val, max_val, 300)\n",
    "    kde = stats.gaussian_kde(x, weights=weights, bw_method=bandwidth)\n",
    "    fes = - kde.logpdf(x_grid)\n",
    "\n",
    "    # apply distance correction\n",
    "    fes += 2 * np.log(x_grid)\n",
    "\n",
    "    # set minimum to zero\n",
    "    fes -= np.nanmin(fes)\n",
    "\n",
    "    return x_grid, fes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fe_diff(cv: np.ndarray, pmf: np.ndarray, lower_well: tuple[float, float], upper_well: tuple[float, float]) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the difference in free energy between the two wells.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    cv : np.ndarray\n",
    "        Array of collective variable values.\n",
    "    pmf : np.ndarray\n",
    "        Array of free energies as a function of collective variable, assumed to be unitless.\n",
    "    lower_well : tuple[float, float]\n",
    "        Tuple of (min, max) values for the lower well.\n",
    "    upper_well : tuple[float, float]\n",
    "        Tuple of (min, max) values for the upper well.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Difference in free energy between the two wells. Unitless.\n",
    "    \"\"\"\n",
    "    assert len(lower_well) == 2, \"Lower well domain must have upper and lower bounds\"\n",
    "    assert len(upper_well) == 2, \"Upper well domain must have upper and lower bounds\"\n",
    "    assert len(pmf) == len(cv), \"PMF and CV must have the same size\"\n",
    "\n",
    "    # get indices of lower and upper wells\n",
    "    lower_well_idx = np.where((cv > lower_well[0]) & (cv < lower_well[1]))\n",
    "    upper_well_idx = np.where((cv > upper_well[0]) & (cv < upper_well[1]))\n",
    "\n",
    "    # integrate boltzmann factors of wells to get probabilities\n",
    "    boltzmann = np.exp(-pmf)\n",
    "    prob_upper = integrate.simpson(boltzmann[upper_well_idx], x=cv[upper_well_idx])\n",
    "    prob_lower = integrate.simpson(boltzmann[lower_well_idx], x=cv[lower_well_idx])\n",
    "\n",
    "    # calculate free energy difference as log of ratio of probabilities\n",
    "    delta_fe = - np.log(prob_lower / prob_upper)\n",
    "    return delta_fe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-25 13:35:35,417 - notebook - INFO - Initial time for analysis: 0.884 ns\n",
      "2023-10-25 13:35:35,420 - notebook - DEBUG - Number of samples: 7957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aglisman/miniconda3/envs/analysis/lib/python3.10/site-packages/scipy/stats/_kde.py:564: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  self._data_covariance = atleast_2d(cov(self.dataset, rowvar=1,\n",
      "/home/aglisman/miniconda3/envs/analysis/lib/python3.10/site-packages/numpy/lib/function_base.py:2680: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  c *= np.true_divide(1, fact)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array must not contain infs or NaNs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m log\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNumber of samples: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(arr_cv)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# calculate FES for the base replica\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m x_grid, fes \u001b[39m=\u001b[39m fes_dist(\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     arr_cv,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     weights\u001b[39m=\u001b[39;49marr_weight,\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     bandwidth\u001b[39m=\u001b[39;49mbandwidth, \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     min_val\u001b[39m=\u001b[39;49mmin_val, \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     max_val\u001b[39m=\u001b[39;49mmax_val, \n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n",
      "\u001b[1;32m/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb Cell 34\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# calculate KDE of x weighted by weights\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m x_grid \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mlinspace(min_val, max_val, \u001b[39m300\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m kde \u001b[39m=\u001b[39m stats\u001b[39m.\u001b[39;49mgaussian_kde(x, weights\u001b[39m=\u001b[39;49mweights, bw_method\u001b[39m=\u001b[39;49mbandwidth)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m fes \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m kde\u001b[39m.\u001b[39mlogpdf(x_grid)\n\u001b[1;32m     <a href='vscode-notebook-cell:/media/aglisman/Linux_Overflow/home/aglisman/VSCodeProjects/Data-Analysis-Surface/analysis/2-monomer-binding/Acn_0.ipynb#X45sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m \u001b[39m# apply distance correction\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/scipy/stats/_kde.py:207\u001b[0m, in \u001b[0;36mgaussian_kde.__init__\u001b[0;34m(self, dataset, bw_method, weights)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`weights` input should be of length n\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_neff \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\u001b[39m/\u001b[39m\u001b[39msum\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_weights\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m--> 207\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_bandwidth(bw_method\u001b[39m=\u001b[39;49mbw_method)\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/scipy/stats/_kde.py:555\u001b[0m, in \u001b[0;36mgaussian_kde.set_bandwidth\u001b[0;34m(self, bw_method)\u001b[0m\n\u001b[1;32m    551\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m`bw_method` should be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mscott\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39msilverman\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, a scalar \u001b[39m\u001b[39m\"\u001b[39m \\\n\u001b[1;32m    552\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mor a callable.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 555\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_compute_covariance()\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/scipy/stats/_kde.py:567\u001b[0m, in \u001b[0;36mgaussian_kde._compute_covariance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    563\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_data_inv_cov\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    564\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_covariance \u001b[39m=\u001b[39m atleast_2d(cov(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset, rowvar\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m    565\u001b[0m                                        bias\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    566\u001b[0m                                        aweights\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweights))\n\u001b[0;32m--> 567\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_inv_cov \u001b[39m=\u001b[39m linalg\u001b[39m.\u001b[39;49minv(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_covariance)\n\u001b[1;32m    569\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcovariance \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_covariance \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n\u001b[1;32m    570\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minv_cov \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_inv_cov \u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfactor\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/scipy/linalg/_basic.py:939\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    900\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minv\u001b[39m(a, overwrite_a\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, check_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    901\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    902\u001b[0m \u001b[39m    Compute the inverse of a matrix.\u001b[39;00m\n\u001b[1;32m    903\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    937\u001b[0m \n\u001b[1;32m    938\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 939\u001b[0m     a1 \u001b[39m=\u001b[39m _asarray_validated(a, check_finite\u001b[39m=\u001b[39;49mcheck_finite)\n\u001b[1;32m    940\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(a1\u001b[39m.\u001b[39mshape) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mor\u001b[39;00m a1\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m] \u001b[39m!=\u001b[39m a1\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]:\n\u001b[1;32m    941\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mexpected square matrix\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/scipy/_lib/_util.py:287\u001b[0m, in \u001b[0;36m_asarray_validated\u001b[0;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mmasked arrays are not supported\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    286\u001b[0m toarray \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray_chkfinite \u001b[39mif\u001b[39;00m check_finite \u001b[39melse\u001b[39;00m np\u001b[39m.\u001b[39masarray\n\u001b[0;32m--> 287\u001b[0m a \u001b[39m=\u001b[39m toarray(a)\n\u001b[1;32m    288\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m objects_ok:\n\u001b[1;32m    289\u001b[0m     \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype \u001b[39mis\u001b[39;00m np\u001b[39m.\u001b[39mdtype(\u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/analysis/lib/python3.10/site-packages/numpy/lib/function_base.py:603\u001b[0m, in \u001b[0;36masarray_chkfinite\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m    601\u001b[0m a \u001b[39m=\u001b[39m asarray(a, dtype\u001b[39m=\u001b[39mdtype, order\u001b[39m=\u001b[39morder)\n\u001b[1;32m    602\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mchar \u001b[39min\u001b[39;00m typecodes[\u001b[39m'\u001b[39m\u001b[39mAllFloat\u001b[39m\u001b[39m'\u001b[39m] \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39misfinite(a)\u001b[39m.\u001b[39mall():\n\u001b[0;32m--> 603\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    604\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39marray must not contain infs or NaNs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    605\u001b[0m \u001b[39mreturn\u001b[39;00m a\n",
      "\u001b[0;31mValueError\u001b[0m: array must not contain infs or NaNs"
     ]
    }
   ],
   "source": [
    "# extract CV and weight data from base replica\n",
    "df = data.copy()\n",
    "start_time = df[\"time\"].max() * start_frame_perc\n",
    "log.info(f\"Initial time for analysis: {start_time/1e3} ns\")\n",
    "df_fes_in = df[df[\"time\"] >= (df[\"time\"].max() * start_frame_perc)].copy()\n",
    "arr_cv = df_fes_in[cv].to_numpy()\n",
    "arr_weight = df_fes_in[\"weight\"].to_numpy()\n",
    "\n",
    "log.debug(f\"Number of samples: {len(arr_cv)}\")\n",
    "\n",
    "# calculate FES for the base replica\n",
    "x_grid, fes = fes_dist(\n",
    "    arr_cv,\n",
    "    weights=arr_weight,\n",
    "    bandwidth=bandwidth, \n",
    "    min_val=min_val, \n",
    "    max_val=max_val, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convergence of the free energy surface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the free energy difference as a function of time\n",
    "times = np.linspace(start_time + 1000, df[\"time\"].max(), 200)\n",
    "delta_fes = np.zeros(len(times))\n",
    "\n",
    "for i, t in tqdm(enumerate(times), total=len(times)):\n",
    "    # calculate PMF estimate at time t\n",
    "    cv_data = df_fes_in[df_fes_in[\"time\"] <= t][cv].to_numpy()\n",
    "    weight_data = df_fes_in[df_fes_in[\"time\"] <= t][\"weight\"].to_numpy()\n",
    "    x, pmf = fes_dist(\n",
    "            cv_data,\n",
    "            weights=weight_data,\n",
    "            bandwidth=bandwidth, \n",
    "            min_val=min_val, \n",
    "            max_val=max_val, \n",
    "        )\n",
    "\n",
    "    # calculate free energy difference from PMF estimate\n",
    "    delta_fes[i] = fe_diff(\n",
    "        x,\n",
    "        pmf,\n",
    "        lower_well=lower_well,\n",
    "        upper_well=upper_well,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the free energy difference as a function of time\n",
    "fname = \"pmf_diff_dynamics\"\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.set_xlabel(\"Time [ns]\")\n",
    "ax.set_ylabel(r\"$\\Delta F$ [$k_\\mathrm{B} T$]\")\n",
    "ax.set_title(\n",
    "    f\"$F({lower_well[0]} \\leq r \\leq {lower_well[1]}) - F({upper_well[0]} \\leq r \\leq {upper_well[1]})$\", \n",
    "    y=1.03, \n",
    "    fontsize=20,\n",
    ")\n",
    "\n",
    "# add horizontal lines that are delta_fes[-1] +- 0.5\n",
    "ax.axhline(delta_fes[-1] - 0.5, linestyle=\"--\", color=\"k\")\n",
    "ax.axhline(delta_fes[-1] + 0.5, linestyle=\"--\", color=\"k\")\n",
    "# fill in horizontal region between lines with opacity 0.2\n",
    "ax.fill_between(\n",
    "    [times[0]/1e3, times[-1]/1e3],\n",
    "    delta_fes[-1] - 0.5, \n",
    "    delta_fes[-1] + 0.5, \n",
    "    alpha=0.1,\n",
    "    color=\"k\",\n",
    ")\n",
    "# plot delta F\n",
    "ax.plot(times/1e3, delta_fes, linewidth=3)\n",
    "\n",
    "# save figure\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{dir_fig}/{fname}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "fig.savefig(f\"{dir_fig}/{fname}.pdf\", dpi=1200, bbox_inches=\"tight\", transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMF Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot free energy surface\n",
    "fname = \"pmf\"\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_title(\"Potential of Mean Force\", pad=10)\n",
    "ax.set_xlabel(r\"$z$ [nm]\", labelpad=10)\n",
    "ax.set_ylabel(r\"$\\Delta F$ [$k_\\mathrm{B}T$]\", labelpad=10)\n",
    "ax.set_ylim((0, ymax))\n",
    "\n",
    "ax.plot(x_grid, fes, linewidth=3)\n",
    "\n",
    "# save figure\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{dir_fig}/{fname}.png\", dpi=600, bbox_inches=\"tight\")\n",
    "fig.savefig(f\"{dir_fig}/{fname}.pdf\", dpi=1200, bbox_inches=\"tight\", transparent=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the free energy surface as a function of time as a movie\n",
    "fname = f\"{dir_fig}/pmf_movie.mp4\"\n",
    "start_frame = int(start_frame_perc * len(data))\n",
    "\n",
    "# setup figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.set_xlabel(r\"$z$ [nm]\", labelpad=10)\n",
    "ax.set_ylabel(r\"$\\Delta F$ [$k_\\mathrm{B}T$]\", labelpad=10)\n",
    "ax.set_ylim((0, ymax))\n",
    "ax.set_title(\"Potential of Mean Force\", pad=10)\n",
    "\n",
    "# initialize plot elements\n",
    "idx = start_frame + step\n",
    "curve = ax.plot(x_grid, np.zeros_like(x_grid), linewidth=3)\n",
    "text = ax.text(0.5, 0.9, f\"$t_f = ${data['time'][idx]/1e3:.2f} ns\", transform=ax.transAxes, ha=\"center\")\n",
    "\n",
    "def animate(frame_num: int):\n",
    "    global idx, start_frame\n",
    "    global curve, text\n",
    "    global data, cv, bandwidth, min_val, max_val\n",
    "\n",
    "    # update curve\n",
    "    _, fes = fes_dist(\n",
    "        data[cv][start_frame:idx].to_numpy(),\n",
    "        weights=data[\"weight\"][start_frame:idx].to_numpy(),\n",
    "        bandwidth=bandwidth, \n",
    "        min_val=min_val, \n",
    "        max_val=max_val,\n",
    "    )\n",
    "    curve[0].set_ydata(fes)\n",
    "\n",
    "    # update text\n",
    "    time = data[\"time\"].loc[idx] / 1e3\n",
    "    text.set_text(f\"$t_f = $ {time:.1f} ns\")\n",
    "\n",
    "    # update index\n",
    "    idx += step\n",
    "\n",
    "    return curve, text\n",
    "\n",
    "\n",
    "# animate\n",
    "n_frames = (len(data) - start_frame) // step - 2\n",
    "stop_frame = data[start_frame::step].index[-1]\n",
    "log.debug(f\"Number of frames: {n_frames}\")\n",
    "log.debug(f\"Stop frame: {stop_frame}\")\n",
    "log.info(f\"Creating animation\")\n",
    "anim = animation.FuncAnimation(\n",
    "    fig, \n",
    "    animate, \n",
    "    blit=True,\n",
    "    frames=n_frames,\n",
    ")\n",
    "\n",
    "# create tqdm progress bar\n",
    "log.info(f\"Saving animation as {fname}\")\n",
    "prog = tqdm(total=n_frames, desc=\"Saving animation\", unit=\"frame\", dynamic_ncols=True, colour=\"green\")\n",
    "\n",
    "# save animation as mp4 and output tqdm progress bar\n",
    "anim.save(\n",
    "    fname, \n",
    "    writer=\"ffmpeg\", \n",
    "    fps=30, \n",
    "    dpi=300,\n",
    "    progress_callback=lambda i, _: prog.update(1),\n",
    ")\n",
    "plt.close()\n",
    "log.debug(f\"Final time rendered: {data['time'].loc[idx] / 1e3:.2f} ns\")\n",
    "log.debug(f\"Final simulation time: {data['time'].to_numpy()[-1] / 1e3:.2f} ns\")\n",
    "\n",
    "# display video in notebook\n",
    "log.info(f\"Displaying animation\")\n",
    "video = display.Video(fname, embed=True, width=700)\n",
    "display.display(video)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
